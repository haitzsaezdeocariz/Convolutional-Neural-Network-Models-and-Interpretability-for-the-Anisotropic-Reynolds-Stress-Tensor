{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Initial Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7db84a0ec95f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mRetau_train3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mdf_train1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmake_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRetau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnondim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-eps'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mRetau\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mRetau_train1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mdf_train2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmake_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRetau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnondim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-eps'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mRetau\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mRetau_train2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mdf_train3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmake_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRetau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnondim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-eps'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mRetau\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mRetau_train3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7db84a0ec95f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mRetau_train3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mdf_train1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmake_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRetau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnondim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-eps'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mRetau\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mRetau_train1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mdf_train2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmake_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRetau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnondim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-eps'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mRetau\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mRetau_train2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mdf_train3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmake_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRetau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnondim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-eps'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mRetau\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mRetau_train3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Github Paper 1\\Pretrained_models_channel_flow\\utils_preprocess_Apr_1.py\u001b[0m in \u001b[0;36mmake_dataframe\u001b[1;34m(Retau, source, nondim)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../data/{0}_Couette_Retau{1}.txt'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRetau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mchannel_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchannel_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRetau\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0my_plus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstresses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_channel_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1000"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils_preprocess_Apr_1 import make_dataframe\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "#GET DATA\n",
    "\n",
    "numpy_seed = 999\n",
    "np.random.seed(numpy_seed)\n",
    "\n",
    "'''Prepare channel flow data'''\n",
    "#Retau_train = [5200] #Use this to train only with one case\n",
    "Retau_train1 = [1000]\n",
    "Retau_train2 = [2000]\n",
    "Retau_train3 = [5200]\n",
    "\n",
    "df_train1 = pd.concat([make_dataframe(Retau, nondim='k-eps') for Retau in Retau_train1])\n",
    "df_train2 = pd.concat([make_dataframe(Retau, nondim='k-eps') for Retau in Retau_train2])\n",
    "df_train3 = pd.concat([make_dataframe(Retau, nondim='k-eps') for Retau in Retau_train3])\n",
    "df_train1['a'] = df_train1[['a_uv', 'a_uu', 'a_vv', 'a_ww']].values.tolist()\n",
    "df_train2['a'] = df_train2[['a_uv', 'a_uu', 'a_vv', 'a_ww']].values.tolist()\n",
    "df_train3['a'] = df_train3[['a_uv', 'a_uu', 'a_vv', 'a_ww']].values.tolist()\n",
    "\n",
    "Retau_test = [550]\n",
    "df_test = pd.concat([make_dataframe(Retau, nondim='k-eps') for Retau in Retau_test])\n",
    "df_test['a'] = df_test[['a_uv', 'a_uu', 'a_vv', 'a_ww']].values.tolist()\n",
    "\n",
    "# scale up target variable in order for stable training, will consider implementing automatic scaler \n",
    "df_train1['a_uv'] *= 1e1\n",
    "df_train2['a_uv'] *= 1e1   \n",
    "df_train3['a_uv'] *= 1e1   \n",
    "df_test['a_uv'] *= 1e1 \n",
    "df_train1['Re_tau'] *= 1e-8 #-6 a -2\n",
    "df_train2['Re_tau'] *= 1e-8   \n",
    "df_train3['Re_tau'] *= 1e-8   \n",
    "df_test['Re_tau'] *= 1e-8 \n",
    "#Get validation data but can ignore it in this case\n",
    "df_val=df_test\n",
    "\n",
    "#Set random seed\n",
    "torch_seed = 9\n",
    "torch.manual_seed(torch_seed)\n",
    "\n",
    "target_label = ['a_uv'] # or ['a'] (output_len = 1 if 'a_uv'; output_len = 4 if 'a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERT DATA TO THE RIGHT TYPE\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format training1 x\n",
    "xtrain1=df_train1['du_dy'].values\n",
    "xtrain_torch1=torch.from_numpy(xtrain1)\n",
    "xtrain_in1=xtrain_torch1.view(1,1,len(df_train1)).float()\n",
    "#Add Reynolds number\n",
    "re_train1=df_train1['Re_tau'].values\n",
    "re_train1=torch.from_numpy(re_train1)\n",
    "re_train1=re_train1.view(1,1,len(re_train1)).float()\n",
    "xtrain_in1=torch.cat((xtrain_in1,re_train1),dim=1)\n",
    "\n",
    "#Format training1 y+ (for boundary condition enforcement)\n",
    "yplus_train1=df_train1['y+'].values\n",
    "yplus_train_torch1=torch.from_numpy(yplus_train1)\n",
    "yplus_train_in1=yplus_train_torch1.view(1,1,len(df_train1)).float()\n",
    "\n",
    "#Format training1 y\n",
    "ytrain1=df_train1['a_uv'].values\n",
    "ytrain_torch1=torch.from_numpy(ytrain1)\n",
    "ytrain_in1=ytrain_torch1.view(1,1,len(df_train1)).float()\n",
    "\n",
    "#Format training2 x\n",
    "xtrain2=df_train2['du_dy'].values\n",
    "xtrain_torch2=torch.from_numpy(xtrain2)\n",
    "xtrain_in2=xtrain_torch2.view(1,1,len(df_train2)).float()\n",
    "#Add Reynolds number\n",
    "re_train2=df_train2['Re_tau'].values\n",
    "re_train2=torch.from_numpy(re_train2)\n",
    "re_train2=re_train2.view(1,1,len(re_train2)).float()\n",
    "xtrain_in2=torch.cat((xtrain_in2,re_train2),dim=1)\n",
    "\n",
    "#Format training2 y+ (for boundary condition enforcement)\n",
    "yplus_train2=df_train2['y+'].values\n",
    "yplus_train_torch2=torch.from_numpy(yplus_train2)\n",
    "yplus_train_in2=yplus_train_torch2.view(1,1,len(df_train2)).float()\n",
    "\n",
    "#Format training2 y\n",
    "ytrain2=df_train2['a_uv'].values\n",
    "ytrain_torch2=torch.from_numpy(ytrain2)\n",
    "ytrain_in2=ytrain_torch2.view(1,1,len(df_train2)).float()\n",
    "\n",
    "#Format training3 x\n",
    "xtrain3=df_train3['du_dy'].values\n",
    "xtrain_torch3=torch.from_numpy(xtrain3)\n",
    "xtrain_in3=xtrain_torch3.view(1,1,len(df_train3)).float()\n",
    "#Add Reynolds number\n",
    "re_train3=df_train3['Re_tau'].values\n",
    "re_train3=torch.from_numpy(re_train3)\n",
    "re_train3=re_train3.view(1,1,len(re_train3)).float()\n",
    "xtrain_in3=torch.cat((xtrain_in3,re_train3),dim=1)\n",
    "\n",
    "#Format training3 y+ (for boundary condition enforcement)\n",
    "yplus_train3=df_train3['y+'].values\n",
    "yplus_train_torch3=torch.from_numpy(yplus_train3)\n",
    "yplus_train_in3=yplus_train_torch3.view(1,1,len(df_train3)).float()\n",
    "\n",
    "#Format training3 y\n",
    "ytrain3=df_train3['a_uv'].values\n",
    "ytrain_torch3=torch.from_numpy(ytrain3)\n",
    "ytrain_in3=ytrain_torch3.view(1,1,len(df_train3)).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Input Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format validation x\n",
    "xval=df_val['du_dy'].values\n",
    "xval_torch=torch.from_numpy(xval)\n",
    "xval_in=xval_torch.view(1,1,len(df_val)).float()\n",
    "#Add Reynolds number\n",
    "re_trainval=df_val['Re_tau'].values\n",
    "re_trainval=torch.from_numpy(re_trainval)\n",
    "re_trainval=re_trainval.view(1,1,len(re_trainval)).float()\n",
    "xval_in=torch.cat((xval_in,re_trainval),dim=1)\n",
    "\n",
    "#Format validation y+ (for boundary condition enforcement)\n",
    "yplus_val=df_val['y+'].values\n",
    "yplus_val_torch=torch.from_numpy(yplus_val)\n",
    "yplus_val_in=yplus_val_torch.view(1,1,len(df_val)).float()\n",
    "\n",
    "#Format validation y\n",
    "yval=df_val['a_uv'].values\n",
    "yval_torch=torch.from_numpy(yval)\n",
    "yval_in=yval_torch.view(1,1,len(df_val)).float()\n",
    "\n",
    "#Format testing x\n",
    "xtest=df_test['du_dy'].values\n",
    "xtest_torch=torch.from_numpy(xtest)\n",
    "xtest_in=xtest_torch.view(1,1,len(df_test)).float()\n",
    "#Add Reynolds number\n",
    "re_traintest=df_test['Re_tau'].values\n",
    "re_traintest=torch.from_numpy(re_traintest)\n",
    "re_traintest=re_traintest.view(1,1,len(re_traintest)).float()\n",
    "xtest_in=torch.cat((xtest_in,re_traintest),dim=1)\n",
    "\n",
    "#Format testing y+ (for boundary condition enforcement)\n",
    "yplus_test=df_test['y+'].values\n",
    "yplus_test_torch=torch.from_numpy(yplus_test)\n",
    "yplus_test_in=yplus_test_torch.view(1,1,len(df_test)).float()\n",
    "\n",
    "#Format testing y\n",
    "ytest=df_test['a_uv'].values\n",
    "ytest_torch=torch.from_numpy(ytest)\n",
    "ytest_in=ytest_torch.view(1,1,len(df_test)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlength=max(xtrain1.shape[0],xtrain2.shape[0],xtrain3.shape[0],xval.shape[0],xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapex1=xtrain1.shape[0]\n",
    "shapex2=xtrain2.shape[0]\n",
    "shapex3=xtrain3.shape[0]\n",
    "shapexval=xval.shape[0]\n",
    "shapextest=xtest.shape[0]\n",
    "zerostrain1=torch.zeros(1,1,maxlength-xtrain1.shape[0])\n",
    "zerostrain2=torch.zeros(1,1,maxlength-xtrain2.shape[0])\n",
    "zerostrain3=torch.zeros(1,1,maxlength-xtrain3.shape[0])\n",
    "zerosval=torch.zeros(1,1,maxlength-xval.shape[0])\n",
    "zerostest=torch.zeros(1,1,maxlength-xtest.shape[0])\n",
    "\n",
    "zerostrain1_double=torch.zeros(1,2,maxlength-xtrain1.shape[0])\n",
    "zerostrain2_double=torch.zeros(1,2,maxlength-xtrain2.shape[0])\n",
    "zerostrain3_double=torch.zeros(1,2,maxlength-xtrain3.shape[0])\n",
    "zerosval_double=torch.zeros(1,2,maxlength-xval.shape[0])\n",
    "zerostest_double=torch.zeros(1,2,maxlength-xtest.shape[0])\n",
    "# converting the data into GPU format\n",
    "xtrain_in1=torch.cat((xtrain_in1,zerostrain1_double), 2)\n",
    "yplus_train_in1=torch.cat((yplus_train_in1,zerostrain1), 2)\n",
    "ytrain_in1=torch.cat((ytrain_in1,zerostrain1), 2)\n",
    "\n",
    "xtrain_in2=torch.cat((xtrain_in2,zerostrain2_double), 2)\n",
    "yplus_train_in2=torch.cat((yplus_train_in2,zerostrain2), 2)\n",
    "ytrain_in2=torch.cat((ytrain_in2,zerostrain2), 2)\n",
    "\n",
    "xtrain_in3=torch.cat((xtrain_in3,zerostrain3_double), 2)\n",
    "yplus_train_in3=torch.cat((yplus_train_in3,zerostrain3), 2)\n",
    "ytrain_in3=torch.cat((ytrain_in3,zerostrain3), 2)\n",
    "\n",
    "xval_in=torch.cat((xval_in,zerosval_double), 2)\n",
    "yplus_val_in=torch.cat((yplus_val_in,zerosval), 2)\n",
    "yval_in=torch.cat((yval_in,zerosval), 2)\n",
    "\n",
    "xtest_in=torch.cat((xtest_in,zerostest_double), 2)\n",
    "yplus_test_in=torch.cat((yplus_test_in,zerostest), 2)\n",
    "ytest_in=torch.cat((ytest_in,zerostest), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create the Convolutional Neural Network with Boundary Condition Enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE THE MODEL INSIDE A CLASS\n",
    "#import required for the activation functions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CONV_NN_BC(nn.Module):\n",
    "    def __init__(self, structure=None):\n",
    "        super(CONV_NN_BC, self).__init__()\n",
    "\n",
    "        self.fc0=nn.Sequential(\n",
    "                nn.Conv1d(2, 5, 3, 1),\n",
    "                nn.BatchNorm1d(5,affine=True),\n",
    "                nn.ELU(inplace=True))\n",
    "        self.fc1=nn.Sequential(\n",
    "                nn.Conv1d(5, 5, 11, 1),\n",
    "                nn.BatchNorm1d(5,affine=True),\n",
    "                nn.ELU(inplace=True))\n",
    "        self.fc2=nn.Sequential(\n",
    "                nn.Conv1d(5, 10, 31, 1),\n",
    "                nn.BatchNorm1d(10,affine=True),\n",
    "                nn.ELU(inplace=True))\n",
    "        self.fc3=nn.Sequential(\n",
    "                nn.Conv1d(10, 10, 41, 1),\n",
    "                nn.BatchNorm1d(10,affine=True),\n",
    "                nn.ELU(inplace=True))\n",
    "        self.fc4=nn.Sequential(\n",
    "                nn.Conv1d(10, 10, 41, 1),\n",
    "                #nn.BatchNorm1d(10),\n",
    "                nn.ELU(inplace=True))\n",
    "        \n",
    "        \n",
    "        self.final = nn.Conv1d(1,1, 10, stride=10)\n",
    "        self.f = nn.Flatten()\n",
    "        self.zerotensor0=torch.zeros(1,2,1)\n",
    "        self.zerotensor1=torch.zeros(1,5,5)\n",
    "        self.zerotensor2=torch.zeros(1,5,15)\n",
    "        self.zerotensor3=torch.zeros(1,10,20)\n",
    "        self.zerotensor4=torch.zeros(1,10,20)\n",
    "        self.beta=0.1\n",
    "\n",
    "        \n",
    "    def forward(self,x,yplus):\n",
    "        re = x[:,1,:]\n",
    "        x = torch.cat((x,self.zerotensor0), 2)\n",
    "        x = torch.cat((self.zerotensor0,x), 2)\n",
    "        x = self.fc0(x)\n",
    "        #x = torch.cat((x,re),1)\n",
    "        #pad tensor\n",
    "        x = torch.cat((x,self.zerotensor1), 2)\n",
    "        x = torch.cat((self.zerotensor1,x), 2)\n",
    "        #Convolution\n",
    "        x = self.fc1(x)\n",
    "        #pad tensor\n",
    "        x = torch.cat((x,self.zerotensor2), 2)\n",
    "        x = torch.cat((self.zerotensor2,x), 2)\n",
    "        #Convolution\n",
    "        x = self.fc2(x)\n",
    "        #pad tensor\n",
    "        x = torch.cat((x,self.zerotensor3), 2)\n",
    "        x = torch.cat((self.zerotensor3,x), 2)\n",
    "        #Convolution\n",
    "        x = self.fc3(x)\n",
    "        #pad tensor\n",
    "        x = torch.cat((x,self.zerotensor4), 2)\n",
    "        x = torch.cat((self.zerotensor4,x), 2)\n",
    "        #Convolution\n",
    "        x = self.fc4(x)\n",
    "        #Final layer \n",
    "        x = torch.mean(x,dim=0) #reshape tensor to apply transpose\n",
    "        x = torch.transpose(x, 0, 1) #transpose tensor\n",
    "        x = x[None,:,:] #reshape tensor\n",
    "        x = self.f(x) #Flatten\n",
    "        x = x[None,:,:] #reshape tensor\n",
    "        x = self.final(x) #weighted average (set initial weights to 1 and divide by 8)\n",
    "        #output = x\n",
    "        output = (1. - torch.exp(-self.beta * yplus))*x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define new loss function\n",
    "\n",
    "#def my_loss(output, target,y):\n",
    "    #loss = torch.mean(((output - target)**2)/(y+400))\n",
    "#    loss = torch.mean((output - target)**2)\n",
    "#    loss\n",
    "#    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALL MODEL AND DEFINE LOSS AND OPTIMIZER FOR THE FUNCTION\n",
    "# defining the model\n",
    "model = CONV_NN_BC()\n",
    "\n",
    "#CHOOSE CASE (remember to specify case in the first cell Retau_test)\n",
    "#model = torch.load('short_convbcre_first') #for test 5200\n",
    "#model = torch.load('short_convbcre_second') #for test 2000\n",
    "#model = torch.load('short_convbcre_third') #for test 1000\n",
    "model = torch.load('short_convbcre_fourth') #for test 550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  \t train: 0.9999472030742749 val: 0.9949096453250155 test: 0.9949096453250155\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "xtrain_in1=xtrain_in1[:,:,0:shapex1]\n",
    "xtrain_in2=xtrain_in2[:,:,0:shapex2]\n",
    "xtrain_in3=xtrain_in3[:,:,0:shapex3]\n",
    "yplus_train_in1=yplus_train_in1[:,:,0:shapex1]\n",
    "yplus_train_in2=yplus_train_in2[:,:,0:shapex2]\n",
    "yplus_train_in3=yplus_train_in3[:,:,0:shapex3]\n",
    "ytrain_in1=ytrain_in1[:,:,0:shapex1]\n",
    "ytrain_in2=ytrain_in2[:,:,0:shapex2]\n",
    "ytrain_in3=ytrain_in3[:,:,0:shapex3]\n",
    "\n",
    "\n",
    "xval_in=xval_in[:,:,0:shapexval]\n",
    "yplus_val_in=yplus_val_in[:,:,0:shapexval]\n",
    "yval_in=yval_in[:,:,0:shapexval]\n",
    "\n",
    "xtest_in=xtest_in[:,:,0:shapextest]\n",
    "yplus_test_in=yplus_test_in[:,:,0:shapextest]\n",
    "ytest_in=ytest_in[:,:,0:shapextest]\n",
    "\n",
    "a_train1=model(xtrain_in1,yplus_train_in1)\n",
    "a_train2=model(xtrain_in2,yplus_train_in2)\n",
    "a_train3=model(xtrain_in3,yplus_train_in3)\n",
    "a_train=torch.cat((a_train1,a_train2,a_train3),2)\n",
    "a_train=torch.mean(a_train, dim=0)\n",
    "a_train=torch.mean(a_train, dim=0)\n",
    "b_train=torch.cat((ytrain_in1,ytrain_in2,ytrain_in3),2)\n",
    "b_train=torch.mean(b_train, dim=0)\n",
    "b_train=torch.mean(b_train, dim=0)\n",
    "\n",
    "a_val=model(xval_in,yplus_val_in)\n",
    "a_val=torch.mean(a_val, dim=0)\n",
    "a_val=torch.mean(a_val, dim=0)\n",
    "b_val=torch.mean(yval_in, dim=1)\n",
    "b_val=torch.mean(b_val, dim=0)\n",
    "test_performance=criterion(ytest_in,model(xtest_in,yplus_test_in))\n",
    "a_test=torch.mean(model(xtest_in,yplus_test_in), dim=0)\n",
    "a_test=torch.mean(a_test, dim=0)\n",
    "b_test=torch.mean(ytest_in, dim=1)\n",
    "b_test=torch.mean(b_test, dim=0)\n",
    "a_train=a_train.cpu().detach().numpy() \n",
    "b_train=b_train.cpu().detach().numpy()\n",
    "a_val=a_val.cpu().detach().numpy() \n",
    "b_val=b_val.cpu().detach().numpy()\n",
    "a_test=a_test.cpu().detach().numpy() \n",
    "b_test=b_test.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print('R^2: ','\\t', 'train:', r2_score(b_train,a_train), 'val:', r2_score(b_val,a_val), 'test:', r2_score(b_test,a_test))\n",
    "\n",
    "\n",
    "\n",
    "test_performance_piecewise=np.zeros_like(a_test)\n",
    "for i in range(len(a_test)):\n",
    "####################################################################################   \n",
    "    test_performance_piecewise[i]=criterion(ytest_in[0,0,i],model(xtest_in,yplus_test_in)[0,0,i])\n",
    "####################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
